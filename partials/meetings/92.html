
<div>
  <div page="1" class="section">
    <div class="centered">
      <div class="container">
        <div class="row">
          <div class="span12">
            <h4>92 spotkanie WJUGa</h4>
            <h2>Inauguracja WHUG: Quick Start with Hadoop, czyli chciałbym, ale się boję</h2>
            <h3>Paweł Brach, Adam Kawa i Tomasz Uliński </h3>
            <p>Termin: 17.04.2012 godz. 18:00</p>
            <p>Lokalizacja: MIMUW, sala 3180 </p>
            <p></p><strong>Sponsor: </strong>
            <ul>
              <li><a href="http://taptera.com/" target="_blank">Taptera</a></li>
            </ul>
            <p></p><strong>Dyskusja:</strong>
            <ul>
              <li><a href="https://groups.google.com/forum/#!topic/warszawa-jug/7SoTtT-6UG0" target="_blank">dyskusja</a></li>
            </ul>
            <h3>O wykładzie:</h3>
            <p>Paweł Brach opowie tytułem wprowadzenia o paradygmacie <a href="http://code.google.com/intl/pl-PL/edu/parallel/mapreduce-tutorial.html" target="_blank">MapReduce </a>i przedstawi ciekawe Facebook’owe zastosowanie <a href="http://hadoop.apache.org/" target="_blank">Hadoop’a</a>. Przyjrzymy się również narzędziom tworzącym tzw. <a href="http://indoos.wordpress.com/2010/08/16/hadoop-ecosystem-world-map/" target="_blank">Hadoop Ecosystem</a>.</p>
            <p>Tomek Uliński pokaże jak napisać pierwszego job’a w Eclipse IDE, jak go lokalnie uruchomić oraz jak napisać do niego unit testy. Następnie skonfigurujemy wspólnie lokalny “klaster” w trybie pseudo-distributed i nauczymy się przełączać między różnymi konfiguracjami.  Zostaną także omówione podstawy debugowania job’ów map-reduce’owych.</p>
            <p>Adam Kawa opowie o usłudze <a href="http://aws.amazon.com/elasticmapreduce/ " target="_blank">Amazon Elastic MapReduce (Amazon EMR)</a>, która pozwala w szybki,  wygodny i niedrogi sposób uruchomić Hadoop’owe aplikacje na wielu jednostkach obliczeniowych, płacąc jedynie za czas wykonywania obliczeń. Dodatkowo, możliwości oferowane przez Amazon EMR zostaną pokazane na przykładzie prostej aplikacji uruchomionej na klastrze składającym się z kilku węzłów.</p>
            <h3>O prelegencie:</h3>
            <p>Adam Kawa jest absolwentem informatyki Uniwersytetu Warszawskiego. Swoją przygodę z Hadoop’em rozpoczął w Netezza/IBM, a od niedawna pracuje w ICM UW, gdzie wykorzystuje Hadoop’a do zadań związanych z przechowywaniem i analizowaniem treści dużych kolekcji dokumentów (publikacji naukowych), o czym można przeczytać na <a href="http://test.blog.ceon.pl/" target="_blank">blogu</a>.</p>
            <p>Paweł Brach jest doktorantem na MIM UW. W Netezza/IBM zajmuje się integracją technologii przechowywania i masowego przetwarzania danych. W wolnym czasie zwiedza Polskę i Europę na motocyklu.</p>
            <p>Tomek Uliński zajmuje się Hadoop’em od 2 lat - prowadzi projekt, będący implementacją paradygmatu MapReduce na platformę sprzętową IBM Netezza 1000 (<a href="http://www.netezza.com/data-warehouse-appliance-products/twinfin.aspx" target="_blank">Data Warehouse Appliance</a>).</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>